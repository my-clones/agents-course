# Agentes `agents`
***`Thought`-`Action`-`Observation`.***

Um agente √© um sistema que pode 'pensar', planificar e interagir com seu ambiente. Em outras palavras, um agente √© definido por ciclos  **`Pensar`-`Agir`-`Observar`** 


* **Pensamento**: A parte `LLM` do `agente` **decide** qual deve ser o **pr√≥ximo passo**.
* **A√ß√£o**: O `agente` realiza uma **a√ß√£o**, chamando as ferramentas com os argumentos associados.
* **Observa√ß√£o**: O `LLM` **reflete** sobre a resposta da ferramenta.

Os tr√™s componentes trabalham juntos em um **loop cont√≠nuo** at√© que o **objetivo do agente seja alcan√ßado** ou um "erro" seja detectado (ex: falha na comunica√ß√£o).


> üëâ Geralmente, as **regras e diretrizes** s√£o incorporadas diretamente no **prompt do sistema** (`system: ""`), garantindo que cada ciclo obede√ßa a uma l√≥gica definida.


No **prompt do sistema** (`system: ""`), podemos definir:

* O comportamento do `Agente`.
* As `Ferramentas` √†s quais nosso Agente tem acesso, conforme descrito na se√ß√£o anterior.
* O `Ciclo Pensamento-A√ß√£o-Observa√ß√£o`, que incorporamos √†s instru√ß√µes do LLM.

```python
SYSTEM_PROMPT = """Answer the following questions as best you can. 
You have access to the following tools:

get_weather: Get the current weather in a given location

The way you use the tools is by specifying a json blob.
Specifically, this json should have a `action` key (with the name of the tool to use) and a `action_input` key (with the input to the tool going here).

The only values that should be in the "action" field are:
get_weather: Get the current weather in a given location, args: {{"location": {{"type": "string"}}}}
example use :

'''
{{
  "action": "get_weather",
  "action_input": {"location": "New York"}
}}

ALWAYS use the following format:

QUESTION: the input question you must answer
THOUGHT: you should always think about one action to take. Only one action at a time in this format:
Action:
'''

$JSON_BLOB

OBSERVATION: the result of the action. This Observation is unique, complete, and the source of truth.
... (this Thought/Action/Observation can repeat N times, you should take several steps when needed. The $JSON_BLOB must be formatted as markdown and only use a SINGLE action at a time.)

You must always end your output with the following format:

THOUGHT: I now know the final answer

FINAL ANSWER: the final answer to the original input question

Now begin! Reminder to ALWAYS use the exact characters `FINAL ANSWERr:` when you provide a definitive answer. 
"""
```

### Example:

Let‚Äôs take a small example to understand the process before going deeper into each step of the process:


***REVIEW THE MERMAID FLOW - PROCESS***

```mermaid
```


**Integra√ß√£o de Ferramentas**
A capacidade de chamar uma ferramenta (como uma API de previs√£o do tempo) permite que o `agente` Alfred v√° al√©m do conhecimento e recupere **dados em tempo real**, um aspecto essencial de muitos Agentes de IA.


**Adapta√ß√£o Din√¢mica**
Cada ciclo permite que o `agente` incorpore novas informa√ß√µes (`observa√ß√µes`) ao seu racioc√≠nio (`pensamento`), garantindo que a resposta final seja bem informada e precisa.

> Este exemplo demonstra o conceito central por tr√°s do ciclo ReAct: 
> A*intera√ß√£o entre `Pensamento`, `A√ß√£o` e `Observa√ß√£o` **capacita os agentes de IA** a resolver tarefas complexas iterativamente.

## ReAct

A abordagem **`ReAct`**, uma t√©cnica de prompting que incentiva o modelo a pensar "passo a passo" antes de **`agir`** e antes de permitir que o **`LLM`** decodifique os pr√≥ximos tokens para resposta final.

Quando um `LLM` √© guiado a pensar "passo a passo", envorajando um processo de decodifica√ß√£o em dire√ß√£o aos pr√≥ximos tokens que geram um plano, em vez de uma solu√ß√£o final, j√° que o `LLM` √© incentivado a decompor o problema em subtarefas antes.

> **üîÑ Ciclo ReAct**
> A intere√ß√£o entre **`Thought`**, **`Action`**, and **`Observation`** capacita os agentes de IA a resolver tarefas complexas de forma iterativa

```mermaid
flowchart LR
    A[User]:::noteStyle
    B[Thought]
    C[Action]
    D[Observation]
    E[User]:::noteStyle

    A--> B --> C --> D --> E
    D --> B

    classDef noteStyle fill:#fff5c2,stroke:#333,stroke-dasharray: 5 5;
```

üî∂ Temos visto **recentemente um grande interesse por <u>estrat√©gias de racioc√≠nio</u>**. √â isso que est√° por tr√°s de modelos como o `Deepseek R1` ou o `o1` da OpenAI, que foram **fine-tuned** (aprimorados) para **"pensar antes de responder"**.

Esses modelos foram treinados para sempre incluir **`se√ß√µes de pensamento`** espec√≠ficas, entre os tokens especiais **`<think>`** ... **`</think>`**. 

Esta **n√£o √© apenas uma t√©cnica de prompt como o ReAct**, **mas um m√©todo de treinamento em que o modelo aprende a gerar essas se√ß√µes** ap√≥s analisar milhares de exemplos que mostram o que esperamos que ele fa√ßa.


### Pensamento (`Thought`)

> üß† **Racioc√≠nio Interno do Agente**

Os pensamentos representam o racioc√≠nio interno e os processos de planejamento do agente para resolver a tarefa. 

O **`agente`** utiliza a capacidade do **`LLM`** de analisar informa√ß√µes dispn√≠veus e criar estrat√©gias para atingir seus objetivos. Pense nisso como o di√°logo interno do agente, onde ele considera a tarefa em quest√£o e elabora estrat√©gias para sua abordagem. Por meio desse processo, o **`agente`** pode **decompor problemas complexos em etapas menores e mais gerenci√°veis**, refletir sobre experi√™ncias passadas e ajustar continuamente seus planos com base em novas informa√ß√µes.

**Tipos de Pensamento (exemplos):**

| Tipo | Descri√ß√£o |
| --- | --- |
| **Planejamento** | ‚ÄúPreciso dividir esta tarefa em tr√™s etapas: 1. coletar dados, 2. analisar tend√™ncias, 3. gerar relat√≥rio‚Äù |
| **An√°lise**  | ‚ÄúCom base na mensagem de erro, o problema parece estar nos par√¢metros de conex√£o com o banco de dados‚Äù |
| **Tomada de Decis√£o** | ‚ÄúDadas as restri√ß√µes or√ßament√°rias do usu√°rio, devo recomendar a op√ß√£o intermedi√°ria‚Äù |
| **Resolu√ß√£o de Problemas** | ‚ÄúPara otimizar este c√≥digo, devo primeiro cri√°-lo para identificar gargalos‚Äù |
| **Integra√ß√£o de Mem√≥ria** | ‚ÄúO usu√°rio mencionou sua prefer√™ncia por Python anteriormente, ent√£o fornecerei exemplos em Python‚Äù |
| **Autorreflex√£o** | ‚ÄúMinha √∫ltima abordagem n√£o funcionou bem, devo tentar uma estrat√©gia diferente‚Äù |
| **Defini√ß√£o de Metas** |‚ÄúPara concluir esta tarefa, preciso primeiro estabelecer os crit√©rios de aceita√ß√£o‚Äù |
| **Prioriza√ß√£o** | ‚ÄúA vulnerabilidade de seguran√ßa deve ser corrigida antes da adi√ß√£o de novos recursos‚Äù |

### A√ß√£o (`Action`)

> ‚ñ∂Ô∏è  **Como o agente interaja com seu ambiente**

As a√ß√µes representam as decis√µes e acoes do agente para atingir seus objetivos.

### Observa√ß√£o (`Observation`)

> üßê ** como um Agente percebe os resultados de suas a√ß√µes**

As observa√ß√µes representam os resultados das a√ß√µes e os dados coletados ao longo do processo.


